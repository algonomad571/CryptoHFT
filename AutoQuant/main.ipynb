{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f48edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Saved 2500 rows to BNBUSDT_last_2500.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def fetch_binance_klines(symbol, interval, limit, end_time_ms=None):\n",
    "    url = \"https://api.binance.com/api/v3/klines\"\n",
    "    params = {\n",
    "        \"symbol\": symbol,\n",
    "        \"interval\": interval,\n",
    "        \"limit\": limit,\n",
    "    }\n",
    "    if end_time_ms:\n",
    "        params[\"endTime\"] = end_time_ms\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Request failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_last_2500_1m(symbol=\"BNBUSDT\", interval=\"1m\", file=\"BNBUSDT_last_2500.csv\"):\n",
    "    all_data = []\n",
    "\n",
    "    # Step 1: Fetch latest 1000 candles\n",
    "    data_1 = fetch_binance_klines(symbol, interval, 1000)\n",
    "    if not data_1:\n",
    "        print(\"🚫 Failed to fetch latest 1000 candles.\")\n",
    "        return\n",
    "    all_data.extend(data_1)\n",
    "\n",
    "    # Step 2: Fetch previous 1000 candles\n",
    "    end_time_2 = int(data_1[0][0]) - 1\n",
    "    data_2 = fetch_binance_klines(symbol, interval, 1000, end_time_ms=end_time_2)\n",
    "    if not data_2:\n",
    "        print(\"🚫 Failed to fetch previous 1000 candles.\")\n",
    "        return\n",
    "    all_data = data_2 + all_data\n",
    "\n",
    "    # Step 3: Fetch previous 500 candles before those\n",
    "    end_time_3 = int(data_2[0][0]) - 1\n",
    "    data_3 = fetch_binance_klines(symbol, interval, 500, end_time_ms=end_time_3)\n",
    "    if not data_3:\n",
    "        print(\"🚫 Failed to fetch previous 500 candles.\")\n",
    "        return\n",
    "    all_data = data_3 + all_data\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_data, columns=[\n",
    "        \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "        \"close_time\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "        \"taker_buy_base_volume\", \"taker_buy_quote_volume\", \"ignore\"\n",
    "    ])\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit='ms')\n",
    "\n",
    "    df.to_csv(file, index=False)\n",
    "    print(f\"📁 Saved {len(df)} rows to {file}\")\n",
    "\n",
    "# 🔧 Run this\n",
    "download_last_2500_1m()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db0afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:43:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classification Report (Buy/Sell/Hold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Buy       0.06      0.01      0.02       502\n",
      "        Hold       0.91      0.89      0.90     10758\n",
      "        Sell       0.05      0.10      0.06       536\n",
      "\n",
      "    accuracy                           0.82     11796\n",
      "   macro avg       0.34      0.34      0.33     11796\n",
      "weighted avg       0.84      0.82      0.83     11796\n",
      "\n",
      " Confusion Matrix:\n",
      "[[   7   31  464]\n",
      " [  18   52  466]\n",
      " [  95 1035 9628]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"BNBUSDT_1m_6months.csv\", parse_dates=[\"timestamp\"], index_col=\"timestamp\")\n",
    "df = df.sort_index()\n",
    "\n",
    "for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "# HAC\n",
    "df[\"HA_close\"] = (df[\"open\"] + df[\"high\"] + df[\"low\"] + df[\"close\"]) / 4\n",
    "df[\"HA_open\"] = ((df[\"open\"].shift(1) + df[\"close\"].shift(1)) / 2).fillna(df[\"close\"])\n",
    "\n",
    "# momentum\n",
    "df[\"momentum_10\"] = df[\"close\"] - df[\"close\"].shift(10)\n",
    "df[\"return_1m\"] = df[\"close\"].pct_change()\n",
    "\n",
    "# bbwr\n",
    "rolling_mean = df[\"close\"].rolling(window=20).mean()\n",
    "rolling_std = df[\"close\"].rolling(window=20).std()\n",
    "df[\"bb_upper\"] = rolling_mean + 2 * rolling_std\n",
    "df[\"bb_lower\"] = rolling_mean - 2 * rolling_std\n",
    "df[\"bb_width\"] = df[\"bb_upper\"] - df[\"bb_lower\"]\n",
    "df[\"bb_width_ratio\"] = df[\"bb_width\"] / rolling_mean\n",
    "\n",
    "\n",
    "df[\"future_return\"] = df[\"close\"].shift(-5) / df[\"close\"] - 1\n",
    "\n",
    "df[\"label\"] = np.select(\n",
    "    [\n",
    "        df[\"future_return\"] > 0.002,    \n",
    "        df[\"future_return\"] < -0.002    \n",
    "    ],\n",
    "    [\n",
    "        \"Buy\", \"Sell\"\n",
    "    ],\n",
    "    default=\"Hold\"\n",
    ")\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# tts\n",
    "features = [\"HA_close\", \"HA_open\", \"momentum_10\", \"return_1m\", \"bb_width_ratio\"]\n",
    "X = df[features]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# label encoding \n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y_encoded[:split_idx], y_encoded[split_idx:]\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "\n",
    "print(\" Classification Report (Buy/Sell/Hold):\")\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "\n",
    "print(\" Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_labels, y_pred_labels, labels=[\"Buy\", \"Sell\", \"Hold\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17e7d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca05bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6431cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d8f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
